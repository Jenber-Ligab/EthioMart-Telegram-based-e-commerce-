{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Processing: Handling Amharic text, tokenization, and preprocessing techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To preprocess the scraped Amharic text data for tasks like tokenization, normalization, and handling Amharic-specific linguistic features, we need to follow several preprocessing steps tailored for the language. \n",
    "\n",
    "Here’s how we can approach this task:\n",
    "\n",
    "**Steps to Preprocess Amharic Text**\n",
    "\n",
    "- **Tokenization**: Tokenization is the process of splitting text into individual units such as words or subwords. Since Amharic uses a different script and has some unique linguistic features, tokenizing might need adjustments. \n",
    "    - Use specialized libraries that handle Amharic text or a custom rule-based tokenizer.\n",
    "\n",
    "- **Normalization**: This step involves cleaning and converting the text into a standard format:\n",
    "\n",
    "    - Remove special characters, punctuation, and numbers.\n",
    "    - Normalize similar-looking characters.\n",
    "    - Convert text to a standard form (for example, removing diacritics if necessary).\n",
    "\n",
    "- **Handling Amharic-Specific Features:**\n",
    "\n",
    "    - Amharic, like other Semitic languages, has specific features such as root-and-pattern morphology.\n",
    "\n",
    "    - Handling unique orthographic variants and considering suffixes, prefixes, and infixes in the language.\n",
    "\n",
    "    - Identifying verb conjugations, plural forms, and possessives for better tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "from collections import Counter\n",
    "# Add the 'scripts' directory to the Python path for module imports\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'scripts')))\n",
    "# Import data preprocessor class\n",
    "from amharic_text_processor import AmharicTextPreprocessor # type: ignore\n",
    "from amharic_labeler import AmharicNERLabeler # type: ignore\n",
    "\n",
    "# Set max rows and columns to display\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"Imported libraries and configured logging.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the scraped Telegram data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data = pd.read_csv('../data/telegram_data.csv')\n",
    "# Explore the first five rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the last five rows\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess and tokenizes the amharic message\n",
    "if __name__ == \"__main__\":\n",
    "    # Amharic text sample\n",
    "    amharic_text = \"ሰላም እንዴት ነህ? እንኳን ደህና መጣህ።\"\n",
    "\n",
    "    preprocessor = AmharicTextPreprocessor()\n",
    "\n",
    "    # Preprocess the text\n",
    "    tokens = preprocessor.preprocess_dataframe(data, 'Message')\n",
    "    display(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN \n",
    "\n",
    "data.dropna(subset='Message', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data['preprocessed_message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure there are no NaN values in the preprocessed column\n",
    "preprocessed_texts = tokens['preprocessed_message'].dropna().tolist()\n",
    "df = pd.Series(preprocessed_texts).reset_index(name='message')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the labeler\n",
    "\n",
    "labeler = AmharicNERLabeler()\n",
    "\n",
    "# Ensure there are no NaN values in the preprocessed column\n",
    "preprocessed_texts = tokens['preprocessed_message'].dropna().tolist()\n",
    "df = pd.Series(preprocessed_texts).reset_index(name='message')\n",
    "# df = df.iloc[10:15]\n",
    "df['Tokenized'] = df['message'].apply(lambda x: x.split())\n",
    "# Label the tokens in the DataFrame\n",
    "labeled_df = labeler.label_dataframe(df, 'Tokenized')\n",
    "\n",
    "\n",
    "# Save to CoNLL format\n",
    "labeler.save_conll_format(labeled_df, '../data/labeled_data_conll.conll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df['message'].duplicated().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
